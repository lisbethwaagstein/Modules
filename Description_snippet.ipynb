{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "#pip install langdetect\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import langdetect \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from langdetect import detect\n",
    "\n",
    "final_data = pd.read_csv(r\"C:\\Users\\lisbe\\OneDrive\\11. Semester\\Social Data Science\\Modules\\final_data.csv\", index_col=0).reset_index()\n",
    "df = final_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Control\n",
    "We draw multiple random samples with 10 links each. We check that the jobs we have classified as remote are indeed remote by going in each link and reading through the complete job listing. Notice that many of them are broken links which means we need to go to Jobindex and check whether they kept a copy of the listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4323    https://dk.indeed.com/viewjob?jk=3c6f929aa17c3...\n",
       "5172    https://www.jobindex.dk/jobannonce/273347/vice...\n",
       "3272    http://www.hammerandersen.com/list/372/ledige-job\n",
       "8049    https://www.regnskabsspecialisten.dk/controlle...\n",
       "8446           http://go.dk/job/638346/c3-consulting-aps/\n",
       "4694    http://jobbank.dk/job/664674/university-of-cam...\n",
       "8027    http://www2.forsvaret.dk/job/ledige_stillinger...\n",
       "1138    https://careers.peopleclick.com/careerscp/clie...\n",
       "1591                   https://www.hansentoft.dk/job/3842\n",
       "4611        https://thehub.dk/jobs/social-media-intern-29\n",
       "Name: Link, dtype: object"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Link'].sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis\n",
    "\n",
    "We begin by cleaning the snippets of job descriptions as much as possible by removing noisy terms such as symbols, numbers and stopwords. Part of this preprocessing also consists in separating the Danish and English job descriptions such that we can remove the relevant stop words for each language and also find the most common words for each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Removing job title and company info from the description column\n",
    "# Detecting language\n",
    "df['Language'] = ''\n",
    "for i in range(len(df)):\n",
    "    #df['Description'][i] = str(df['Description'][i]).replace(df['Job Title'][i],'')\n",
    "    df['Description'][i] = str(df['Description'][i]).replace(df['Company'][i],'')\n",
    "    df['Description'][i] = str(df['Description'][i]).strip()\n",
    "    if len(df['Description'][i]) > 10:\n",
    "        df['Language'][i] = detect(str(df['Description'][i]))\n",
    "    else:\n",
    "        df['Language'][i] = 'da'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Some job postings were mistakenly classified as languages other than english or danish when they were actually danish:\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['Language'][i] != 'da' and df['Language'][i] != 'en': \n",
    "        df['Language'][i] = 'da'\n",
    "        \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer_da = SnowballStemmer(\"danish\")\n",
    "stemmer_en = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\lisbe\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Now we clean the descriptions as much as we can, tokenize them and stem them using the snowball stemmer\n",
    "symbols = ['?','!','>','<','-','[',']','(',')','{','}',' –','``',\"''\",'\"\"','\\\\','@','$','&','=']\n",
    "useless_words = ['søger', 'vores', '.', 'kunder','jobcenter','arbejde','dine', 'får', 'samt', 'del','inden', 's', 'danmark','dit', 'både', 'ved','inden' ,'søges', 'a', 's', 'få', 'kan', 'så', 'opgaver',\\\n",
    "                 'jobsincopenhagen' ,'looking', 'denmark', 'work','company','eksiterende','spændende']\n",
    "df['Tokenized_description'] = ''\n",
    "for i in range(len(df)):\n",
    "    stop_words_da = nltk.corpus.stopwords.words(\"danish\")\n",
    "    stop_words_en = nltk.corpus.stopwords.words(\"english\")\n",
    "    df['Tokenized_description'][i] = re.sub(r'(\\.+ )|,|\\||:|/|\\'|\\-|;|\\*|!|(\\s\\d+\\s)|(\\s\\W\\s)',' ',str(df['Description'][i]))\n",
    "    df['Tokenized_description'][i] = str(df['Tokenized_description'][i]).rstrip('\\\\')\n",
    "    df['Tokenized_description'][i] = nltk.word_tokenize(str(df['Tokenized_description'][i].lower()))\n",
    "    df['Tokenized_description'][i] = [w for w in df['Tokenized_description'][i] if not w in symbols]\n",
    "    df['Tokenized_description'][i] = [w for w in df['Tokenized_description'][i] if not w.isnumeric()]\n",
    "    df['Tokenized_description'][i] = [w for w in df['Tokenized_description'][i] if not w in useless_words]\n",
    "    if df['Language'][i] == 'da':\n",
    "        df['Tokenized_description'][i] = [w for w in df['Tokenized_description'][i] if not w in stop_words_da]\n",
    "        #df['Tokenized_description'][i] = [stemmer_da.stem(w) for w in df['Tokenized_description'][i]]\n",
    "    else:\n",
    "        df['Tokenized_description'][i] = [w for w in df['Tokenized_description'][i] if not w in stop_words_en]\n",
    "        #df['Tokenized_description'][i] = [stemmer_en.stem(w) for w in df['Tokenized_description'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_da_tok = df_da['Tokenized_description'].tolist()\n",
    "words_en_tok = df_en['Tokenized_description'].tolist()\n",
    "\n",
    "# Putting all words from all documents into the same list\n",
    "flat_list_da = [item for sublist in words_da_tok for item in sublist] \n",
    "flat_list_en = [item for sublist in words_en_tok for item in sublist]\n",
    "\n",
    "#Finding the most common words\n",
    "from collections import Counter\n",
    "top_en = Counter(flat_list_en).most_common(20)\n",
    "top_da = Counter(flat_list_da).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Since we have already pre processed our data, we will use the vectorizer without it tokenizing our data\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "# We split the datasets according to language\n",
    "df_da = df[df['Language']=='da']\n",
    "df_en = df[df['Language']=='en']\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None,\n",
    "    max_df=0.95,\n",
    "    min_df=0.04,\n",
    "    max_features=10)  \n",
    "\n",
    "vectors_da = tfidf.fit_transform(words_da_tok)\n",
    "vocabulary_da = tfidf.vocabulary_\n",
    "print(vocabulary_da)\n",
    "\n",
    "vectors_den = tfidf.fit_transform(words_en_tok)\n",
    "vocabulary_en = tfidf.vocabulary_\n",
    "print(vocabulary_en)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "bag = count.fit_transform(df['Tokenized_description'])\n",
    "print(count.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
