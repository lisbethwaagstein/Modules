{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** In most sessions you will be solving exercises posed in a Jupyter notebook that looks like this one. Because you are cloning a Github repository that only we can push to, you should **NEVER EDIT** any of the files you pull from Github. Instead, what you should do, is either make a new notebook and write your solutions in there, or **make a copy of this notebook and save it somewhere else** on your computer, not inside the `sds` folder that you cloned, so you can write your answers in there. If you edit the notebook you pulled from Github, those edits (possible your solutions to the exercises) may be overwritten and lost the next time you pull from Github. This is important, so don't hesitate to ask if it is unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 8: Advanced Scrapers\n",
    "\n",
    "In this Exercise Set we shall develop our webscraping skills even further by practicing using `Selenium` while   parsing and navigating html trees using `BeautifoulSoup`. Furthermore we will train extracting information from raw text with no html tags to help, using regular expressions. \n",
    "\n",
    "But just as importantly you will get a chance to think about **data quality issues** and how to ensure reliability when curating your own webdata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 8.1: Translating domains into companies\n",
    "This exercise is about solving a problem that danish companies are facing. They all want to use external data such as customer review data to gain more knowledge about their customers and maybe even use the information as features in their models. There is just one problem: users rate domains not companies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.1:** You work for the danish authorities and are currently staffed to a project where you have to reduce the amount of dangerous toys. You have build a webscraper that collect user reviews form Trustpilot and have identified some websites that got a bad reputation among its users. You belive that the risk of them selling illegal or dangerous toys might be bigger than some of the bg brands with good ratings and decide to investigate them. \n",
    "\n",
    "> Go to the website https://www.dk-hostmaster.dk/da/find-domaenenavn with selenium and search for \"netbaby.dk\". Store the name of the registrant \"Euphemia Media\" in the variable `company`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.1.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.2:** Now you know who owns the domain and would like to know more about the company `euphemia media`. \n",
    "\n",
    "> Go to the Central Business Register website https://datacvr.virk.dk/data/. Figure out how to look up companies by changing the url and then lookup `euphemia media`. Store the CVR number in the variable `cvr` and print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.1.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.3:** Congratulations. You are now able to translate domains into companies and by that enrich what ever analysis you want to make. Let's say that you were to build a scraper who could translate thousands of domains. What kind of errors can you imagine running into and how would you mitigate them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.1.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 8.2: Practicing Regular Expressions.\n",
    "This exercise is about developing your experience with designing your own regular expressions.\n",
    "\n",
    "Remember you can always consult the regular expression reference page [here](https://www.regular-expressions.info/refquick.html), if you need to remember or understand a specific symbol. \n",
    "\n",
    "You should practice using *\"define-inspect-refine-method\"* described in the lectures to systematically ***explore*** and ***refine*** your expressions, and save all the patterns tried. You can download the small module that I created to handle this in the following way: \n",
    "``` python\n",
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/snorreralund/explore_regex/master/explore_regex.py'\n",
    "response = requests.get(url)\n",
    "with open('explore_regex.py','w') as f:\n",
    "    f.write(response.text)\n",
    "import explore_regex as e_re\n",
    "```\n",
    "\n",
    "Remember to start ***broad*** to gain many examples, and iteratively narrow and refine.\n",
    "\n",
    "We will use a sample of the trustpilot dataset that you practiced collecting yesterday.\n",
    "You can load it directly into python from the following link: https://raw.githubusercontent.com/snorreralund/scraping_seminar/master/english_review_sample.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.1:** Load the data used in the exercise using the `pd.read_csv` function. (Hint: path to file can be both a url or systempath). \n",
    "\n",
    ">Define a variable `sample_string = '\\n'.join(df.sample(2000).reviewBody)` as sample of all the reviews that you will practice on.  (Run it once in a while to get a new sample for potential differences).\n",
    "Imagine we were a company wanting to find the reviews where customers are concerned with the price of a service. They decide to write a regular expression to match all reviews where a currencies and an amount is mentioned. \n",
    "\n",
    "> **Ex. 8.2.2:** \n",
    "> Write an expression that matches both the dollar-sign (\\$) and dollar written literally, and the amount before or after a dollar-sign. Remember that the \"$\"-sign is a special character in regular expressions. Explore and refine using the explore_pattern function in the package I created called explore_regex. \n",
    "```python\n",
    "import explore_regex as e_re\n",
    "explore_regex = e_re.Explore_Regex(sample_string) # Initaizlie the Explore regex Class.\n",
    "explore_regex.explore_pattern(pattern) # Use the .explore_pattern method.\n",
    "```\n",
    "\n",
    "\n",
    "Start with exploring the context around digits (\"\\d\") in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer 8.2.1-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.8.2.3** Use the .report() method. e_re.report(), and print the all patterns in the development process using the .pattern method - i.e. e_re.patterns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[Answer 8.2.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.4** \n",
    "Finally write a function that takes in a string and outputs if there is a match. Use the .match function to see if there is a match (hint if does not return a NoneType object - `re.match(pattern,string)!=None`).\n",
    "\n",
    "> Define a column 'mention_currency' in the dataframe, by applying the above function to the text column of the dataframe. \n",
    "*** You should have approximately 310 reviews that matches. - but less is also alright***\n",
    "\n",
    "> **Ex. 8.2.5** Explore the relation between reviews mentioning prices and the average rating. \n",
    "\n",
    "> **Ex. 8.2.6 (extra)** Define a function that outputs the amount mentioned in the review (if more than one the largest), define a new column by applying it to the data, and explore whether reviews mentioning higher prices are worse than others by plotting the amount versus the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer to 8.2.4-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.7:** Now we write a regular expression to extract emoticons from text.\n",
    "Start by locating all mouths ')' of emoticons, and develop the variations from there. Remember that paranthesis are special characters in regex, so you should use the escape character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[Answer to 8.2.7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
