{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_class\n",
    "import random\n",
    "import time\n",
    "import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "logfile = 'log.csv'## name your log file.\n",
    "connector = scraping_class.Connector(logfile)\n",
    "\n",
    "# First we want a link for each result page in careergate\n",
    "\n",
    "def link_page(n): # defining a function that creates a link for a given page number\n",
    "    link =  f'https://careergate.cbs.dk/da/jobs?remote=1&limit=10&offset={n}'\n",
    "    return link\n",
    "\n",
    "links = [link_page(n) for n in range(0,320,10)] #storing links for all the pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want a list of all the job links in each page \n",
    "\n",
    "job_links = []\n",
    "for link in links : \n",
    "    response,call_id = connector.get(link,'searchpage')\n",
    "    soup = BeautifulSoup(response.text, \"html5lib\") # get html for each page\n",
    "    job_link = soup.find_all('a', class_=\"job-box\") # find all job-box objects\n",
    "    job_links += job_link\n",
    "\n",
    "    \n",
    "jobs = [job_link.get('href') for job_link in job_links] # get all the job links in one list \n",
    "job_links_total = list(dict.fromkeys(jobs)) # remove duplicates\n",
    "len(job_links_total) # make sure this matches with the total from the search page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 'https://careergate.cbs.dk' to the links so that they can be used later \n",
    "url_prefix = 'https://careergate.cbs.dk'\n",
    "job_links_total = [url_prefix + job_link for job_link in job_links_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "job_data = [] # this will eventually be our dataframe\n",
    "\n",
    "for link in job_links_total:\n",
    "    response,call_id = connector.get(link,'job posting')\n",
    "    soup = BeautifulSoup(response.text, \"lxml\") # get html for each page\n",
    "    descrip = soup.find('article', class_ = \"box-item job-content\")#.get_text()\n",
    "    box = soup.find('div', class_ = \"content-description\").get_text()\n",
    "    box = box.replace(\"\\n\", \" \")\n",
    "    box = \" \".join(box.split())\n",
    "    location = re.findall(r'(?<=Sted)(.*)(?=Fjernarbejde)', box)\n",
    "    category = re.findall(r'(?<=Kategori)(.*)(?=Type)', box)\n",
    "    type_ = re.findall(r'(?<=Type)(.*)(?=Kompetencer)', box)\n",
    "    skills = re.findall(r'(?<=Kompetencer)(.*)(?=Must-have sprog)', box)\n",
    "    languages = re.findall(r'(?<=Must-have sprog)(.*)', box)\n",
    "    description = re.findall(r'(?<=<p>)(.*)(?=</p>)', str(descrip))\n",
    "    job = [str(location), str(category), str(type_), str(skills), str(languages), str(description)]\n",
    "    job_data.append(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming into dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(job_data)\n",
    "df.columns = [\"Location\", \"Category\", \"Type\", \"Skills\", \"Language\", \"Description\"]\n",
    "\n",
    "# code to clean the description column from html \n",
    "df['Description'] = [BeautifulSoup(text).get_text() for text in df['Description'] ]\n",
    "\n",
    "# taking all values out of the brackets\n",
    "columns = [\"Location\", \"Category\", \"Type\", \"Skills\", \"Language\", \"Description\"]\n",
    "for column in columns:\n",
    "    df[column] = df[column].str.strip('[]').astype(str)\n",
    "    df[column] = df[column].str.strip(' \"\" ')\n",
    "    df[column] = df[column].str.strip(' '' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
