{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam: Scraping job postings from Jobindex\n",
    "\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_class\n",
    "logfile = 'log_jobindex_scraping.txt'\n",
    "connector = scraping_class.Connector(logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "#define url and fetch the HTML using the requests module\n",
    "url = 'https://www.jobindex.dk/jobsoegning?lang=da.html'\n",
    "response = requests.get(url)  \n",
    "html = response.text  \n",
    "soup = BeautifulSoup(html,'lxml') # parse the raw html using BeautifoulSoup\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n"
     ]
    }
   ],
   "source": [
    "#find the max page number\n",
    "max_page = soup.find('ul',{'class':'pagination'})\n",
    "max_page2 = max_page.find_all('a', {'class':'page-link'})\n",
    "\n",
    "def convert_value_type(value_node):\n",
    "    if value_node.name == 'a':\n",
    "        return value_node.text\n",
    "\n",
    "page_list = []\n",
    "for page in max_page2:\n",
    "    page_list.append(convert_value_type(page))\n",
    "#print(page_list[-1])\n",
    "\n",
    "last_page = int(page_list[-1]) + 1 # we add one to use it in range in for-loop\n",
    "print(last_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "https://stormgroup.recruitee.com/o/salgskonsulent-til-sjov-social-hverdag\" data-click=\"/c?t=h989946&amp;ctx=w&amp;u=20313204\" rel=\"noopener\" target=\"_blank\"><b>salgskonsulent til sjov, social hverdag</b></a>\n",
      "<p>\n",
      "<a \n",
      "https://ikast-brande.emply.net/recruitment/vacancyad.aspx?publishingid=1fb545a3-1946-4afc-8484-9c336901cb5b\n",
      "https://ikast-brande.emply.net/recruitment/vacancyad.aspx?publishingid=5346be46-89e6-4202-aa7e-5f497d5ada6b\n",
      "https://www.jobindex.dk/jobannonce/366043/socialfaglig-medarbejder\n",
      "https://www.birn-partners.com/jobs/?hr=show-job%2f59547&amp;locale=da_dk\n",
      "https://www.jobindex.dk/jobannonce/366045/udekoerende-daekmontoer-til-alsidigt-arbejde\n",
      "https://www.innomate.com/innomatepublicpagesmedarb/jobnotice.aspx?companyid=zbc&amp;jobnoticeid=477\n",
      "https://www.innomate.com/innomatepublicpagesmedarb/jobnotice.aspx?companyid=zbc&amp;jobnoticeid=479\n",
      "https://candidate.hr-manager.net/applicationinit.aspx?cid=5001&amp;projectid=134384&amp;departmentid=7957&amp;mediaid=5&amp;skipadvertisement=false\n",
      "https://www.odense.dk/job?vacancyid=27322\n",
      "https://www.innomate.com/innomatepublicpagesmedarb/jobnotice.aspx?companyid=sde&amp;jobnoticeid=1176\n",
      "https://candidate.hr-manager.net/applicationinit.aspx?cid=1627&amp;projectid=143600&amp;departmentid=18956&amp;mediaid=4619\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-af90b78b6159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m#for link in links[i][1]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m    \u001b[1;31m# all_links.add(split('\"')[0]) # this is where the link to the job posting is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#check exercise 6.1.4??\n",
    "#Get all link pages from jobindex\n",
    "jobindex_links = []\n",
    "for i in range(1,last_page):\n",
    "    url = f'https://www.jobindex.dk/jobsoegning?lang=da?page={i}.html'\n",
    "    jobindex_links.append(url)   \n",
    "#print(jobindex_links)\n",
    "\n",
    "#Extract data from one page link first. We want the\n",
    "url = 'https://www.jobindex.dk/jobsoegning?lang=da?page=1.html'\n",
    "response = requests.get(url)  \n",
    "html = response.text  \n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "#one job result is given by class=jobsearch-result\n",
    "joblistings = soup.find_all('div',{'class':'jobsearch-result'})\n",
    "#print(joblistings)\n",
    "\n",
    "# now find the a href hyperlinks of the individual jos postings. note: postings have many hyperlinks.\n",
    "#first divide into postings in a list\n",
    "postings = []\n",
    "for posting_loc in html.split('<div class=\"jobsearch-result\">')[1:]:\n",
    "    posting = posting_loc.split('</div>')[0].lower()\n",
    "    postings.append(posting)\n",
    "#print(postings)\n",
    "\n",
    "#now find all hyperlinks within a posting\n",
    "links = []\n",
    "for posting in postings:\n",
    "    link_loc = tuple(posting.split('href=\"')[1:])    #this is made into a tuple to be able to call the second element.\n",
    "    #link_loc2 = link_loc.split('\"')[0]\n",
    "    links.append(link_loc) \n",
    "print(len(links)) # there is 20 postings per page\n",
    "#print(links)\n",
    "\n",
    "#want to get the second element in all the \"links\" such as:\n",
    "#print(links[1][1])\n",
    "#print(links[2][1])\n",
    "print(links[14][1])\n",
    "\n",
    "all_links = []\n",
    "for i in range(1,len(links)):\n",
    "    #for link in links[i][1]:\n",
    "    print(links[i][1].split('\"')[0])\n",
    "        \n",
    "   # all_links.add(split('\"')[0]) # this is where the link to the job posting is\n",
    "\n",
    "#we have to replace \"amp\" in all links with \"\"\n",
    "   \n",
    "'''    \n",
    "    for link in link_loc:\n",
    "    second_link = link[.split('\"')[0]\n",
    "    links.append(second_link)\n",
    "print(links)\n",
    "#for link in links:\n",
    "#    link_done = link.split('\"')[0]\n",
    "#    all_links.append(link_done)\n",
    "#print(all_links) \n",
    " #   link = link.split('\"')[0]\n",
    "'''\n",
    "'''for link_loc in postings_join.split('href=\"')[1:]:\n",
    "    link = link_loc.split('\"')[0]\n",
    "    links.add(link)\n",
    "print(links)'''\n",
    "\n",
    "'''for link_loc in \n",
    "    link = link_loc.split('\"')[0]\n",
    "    if '/categories/' in link:\n",
    "        links.add(link)\n",
    "print(len(links),list(links)[0]) # link is relative\n",
    "links = ['https://www.trustpilot.com'+link for link in links]# add the domain to each link\n",
    "links[:10]\n",
    "'''\n",
    "'''\n",
    "url = 'https://www.jobindex.dk/jobsoegning?lang=da?page=1.html'\n",
    "response, call_id = connector.get(url,'mapping_categories')\n",
    "if response.ok:\n",
    "    html = response.text\n",
    "else:\n",
    "    print('error')\n",
    "'''                                      \n",
    "'''\n",
    "#Extract data from all the links\n",
    "jobindex_data = []\n",
    "for link in jobindex_links:\n",
    "    response = requests.get(link)  \n",
    "    html = response.text  \n",
    "    soup = BeautifulSoup(html,'lxml') # parse the raw html using BeautifoulSoup\n",
    "    \n",
    "    #print(soup) '''   \n",
    "https://candidate.hr-manager.net/ApplicationInit.aspx?cid=1627&ProjectId=143600&DepartmentId=18956&MediaId=4619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting slate3kNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading slate3k-0.5.3-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting pdfminer3k\n",
      "  Downloading pdfminer3k-1.3.4-py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: ply in c:\\users\\miche\\anaconda3\\lib\\site-packages (from pdfminer3k->slate3k) (3.11)\n",
      "Installing collected packages: pdfminer3k, slate3k\n",
      "Successfully installed pdfminer3k-1.3.4 slate3k-0.5.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pip install slate3k\n",
    "#pip install PyPDF2\n",
    "#pip install textract\n",
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot locate objid=59\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import slate3k as slate\n",
    "#request the url\n",
    "url = 'https://www.jobindex.dk/img/pdf/LRS210820SOC.pdf'\n",
    "response = requests.get(url)\n",
    "\n",
    "#save the pdf in the current folder\n",
    "with open('pdf.pdf', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "#open the pdf and get the text in doc\n",
    "with open('pdf.pdf', 'rb') as fp:\n",
    "    doc = slate.PDF(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GolfBox A/S blev stiftet i 2003 og er siden blevet Skandinaviens største leverandør af administrationssoftware til golfklubber. GolfBox A/S™ software er 100% internetbaseret, hvilket bl.a. har medvirket til et stort teknologisk forspring i branchen globalt www.golfbox.netco@golfbox.dk. Sammen HenvendelseVi er i øjeblikket 19 engagerede medarbejdere hos GolfBox A/S.GolfBox A/S søger ambitiøs Programmør / Datamatiker+45 2173 4000 info@GolfBox.dk www.GolfBox.netGolfBox A/S Mere tid til golf...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#while loop reads each page and extracts the text\\nwhile count < num_pages:\\n    pageObj = pdfReader.getPage(count)\\n    count +=1\\n    text += pageObj.extractText()\\n    #pdf_text = str(text).replace('\\n','')\\nprint(text)\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import PyPDF2 \n",
    "import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#scraping a PDF file*\n",
    "filename = 'pdf.pdf' \n",
    "\n",
    "#open allows you to read the file.\n",
    "pdfFileObj = open(filename,'rb')\n",
    "\n",
    "#The pdfReader variable is a readable object that will be parsed.\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "#Discerning the number of pages will allow us to parse through all the pages.\n",
    "num_pages = pdfReader.numPages\n",
    "count = 0\n",
    "text = \"\"\n",
    "\n",
    "#while loop reads each page and extracts the text\n",
    "while count < num_pages:\n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "    #pdf_text = str(text).replace('\\n','')\n",
    "print(text)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div aria-expanded=\"true\" class=\"card-body collapse show\" id=\"areas\">\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/storkoebenhavn\" id=\"geoareaid15182\">\n",
      "                Storkøbenhavn<span class=\"counter\" id=\"hits_geoareaid15182\">4828</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/nordsjaelland\" id=\"geoareaid15187\">\n",
      "                Nordsjælland<span class=\"counter\" id=\"hits_geoareaid15187\">1111</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/region-sjaelland\" id=\"geoareaid4\">\n",
      "                Region Sjælland<span class=\"counter\" id=\"hits_geoareaid4\">1389</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/fyn\" id=\"geoareaid15179\">\n",
      "                Fyn<span class=\"counter\" id=\"hits_geoareaid15179\">909</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/region-nordjylland\" id=\"geoareaid3\">\n",
      "                Region Nordjylland<span class=\"counter\" id=\"hits_geoareaid3\">918</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/region-midtjylland\" id=\"geoareaid2\">\n",
      "                Region Midtjylland<span class=\"counter\" id=\"hits_geoareaid2\">2801</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/sydjylland\" id=\"geoareaid15180\">\n",
      "                Sydjylland<span class=\"counter\" id=\"hits_geoareaid15180\">1460</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/bornholm\" id=\"geoareaid15\">\n",
      "                Bornholm<span class=\"counter\" id=\"hits_geoareaid15\">35</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/skaane\" id=\"geoareaid16149\">\n",
      "                Skåne<span class=\"counter\" id=\"hits_geoareaid16149\">483</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/groenland\" id=\"geoareaid15271\">\n",
      "                Grønland<span class=\"counter\" id=\"hits_geoareaid15271\">156</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/faeroeerne\" id=\"geoareaid15799\">\n",
      "                Færøerne<span class=\"counter\" id=\"hits_geoareaid15799\">3</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/udlandet\" id=\"geoareaid15185\">\n",
      "                Udlandet<span class=\"counter\" id=\"hits_geoareaid15185\">380</span></a>\n",
      "</div>\n",
      "<div class=\"checkbox-holder\">\n",
      "<a class=\"area_label\" href=\"/jobsoegning/danmark\" id=\"geoareaid1221\">\n",
      "                Danmark<span class=\"counter\" id=\"hits_geoareaid1221\">12508</span></a>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-7fe188251e36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlink_loc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mareas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href=\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_loc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'/jobsoegning/'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#scraping the geographical areas from jobindex\n",
    "url = 'https://www.jobindex.dk/jobsoegning'\n",
    "response, call_id = connector.get(url, 'map_geo')\n",
    "if response.ok:\n",
    "    html = response.text\n",
    "else:\n",
    "    print('error')\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "#one job result is given by class=jobsearch-result\n",
    "areas = soup.find('div', {'id':'areas'}) #use categories for job categories\n",
    "print(areas)    \n",
    "\n",
    "links = set()\n",
    "for link_loc in areas.split('href=\"')[1:]:\n",
    "    link = link_loc.split('\"')[0]\n",
    "    if '/jobsoegning/' in link:\n",
    "        links.add(link)\n",
    "#print(len(links),list(links)[0]) # link is relative\n",
    "links = ['https://www.jobindex.dk'+link for link in links]# add the domain to each link\n",
    "print(links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
